{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "    def __init__(self, max_size, ip_dims, n_acts):\n",
    "        \n",
    "        self.max_size = max_size\n",
    "        self.mean_cntr = 0 \n",
    "        \n",
    "        self.state_memory = np.zeros((self.max_size, *ip_dims))\n",
    "        self.new_state_memory = np.zeros((self.max_size, *ip_dims))\n",
    "        self.action_memory = np.zeros((self.max_size, n_acts))\n",
    "        self.reward_memory = np.zeros(self.max_size)\n",
    "        \n",
    "        self.terminal_mmeory = np.zeros(self.max_size, dtype=np.bool)\n",
    "        \n",
    "    def store_transition(self, state, action, reward, state_, done):\n",
    "        \n",
    "        index = self.mean_cntr % self.max_size\n",
    "        \n",
    "        self.state_memory[index] = state\n",
    "        self.new_state_memory[index] = state_\n",
    "        self.terminal_mmeory[index] = done\n",
    "        self.reward_memory[index] = reward\n",
    "        self.action_memory[index] = action\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.mean_cntr += 1\n",
    "        \n",
    "    \n",
    "    def sample_buffer(self, batch_size):\n",
    "        max_mem = min(self.mean_cntr, self.max_size)\n",
    "        batch = np.random.choice(max_mem, batch_size)\n",
    "        \n",
    "        state = self.state_memory[batch]\n",
    "        state_ = self.new_state_memory[batch]\n",
    "        action = self.action_memory[batch]\n",
    "        reward = self.reward_memory[batch]\n",
    "        dones = self.terminal_mmeory[batch]\n",
    "        \n",
    "        return state, action, reward, state_, dones\n",
    "\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, alpha, ip_dims, n_acts, name):\n",
    "        \n",
    "        super(Actor, self).__init__()\n",
    "        \n",
    "        self.ip_dims = ip_dims\n",
    "        self.name = name\n",
    "        self.n_acts = n_acts\n",
    "        \n",
    "        self.fc1 = nn.Linear(*self.ip_dims, 400)\n",
    "        self.fc2 = nn.Linear(400, 300)\n",
    "        self.mu = nn.Linear(300, self.n_acts)\n",
    "        \n",
    "        self.opt = optim.Adam(self.parameters(), lr=alpha)\n",
    "        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        self.to(self.device)\n",
    "        \n",
    "    \n",
    "    def forward(self, state):\n",
    "        p = self.fc1(state)\n",
    "        p = F.relu(p)\n",
    "        p = self.fc2(p)\n",
    "        p = F.relu(p)\n",
    "        mu = T.tanh(self.mu(p))\n",
    "        \n",
    "        return mu\n",
    "    \n",
    "        \n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, beta, ip_dims, n_acts, name):\n",
    "        \n",
    "        super(Critic, self).__init__()\n",
    "        \n",
    "        self.ip_dims = ip_dims\n",
    "        self.name = name\n",
    "        self.n_acts = n_acts\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.ip_dims[0] + n_acts, 400)\n",
    "        self.fc2 = nn.Linear(400, 300)\n",
    "        self.q1 = nn.Linear(300, 1)\n",
    "        \n",
    "        self.opt = optim.Adam(self.parameters(), lr=beta)\n",
    "        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        self.to(self.device)\n",
    "        \n",
    "    \n",
    "    def forward(self, state, action):\n",
    "        Q = self.fc1(T.cat([state, action], dim=1))\n",
    "        Q = F.relu(Q)\n",
    "        Q = self.fc2(Q)\n",
    "        Q = F.relu(Q)\n",
    "        Q = self.q1(Q)\n",
    "        \n",
    "        return Q\n",
    "    \n",
    "        \n",
    "     \n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, alpha, beta, ip_dims, tau, env,\n",
    "            gamma=0.99, update_actor_interval=2, warmup=1000,\n",
    "            n_actions=2, max_size=1000000, batch_size=100, noise=0.1):\n",
    "        \n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "        \n",
    "        self.max_action = env.action_space.high\n",
    "        self.min_action = env.action_space.low\n",
    "        \n",
    "        self.memory = ReplayBuffer(max_size, ip_dims, n_actions)\n",
    "        self.batch_size =batch_size\n",
    "        self.learning_step_ctr = 0\n",
    "        self.time_step = 0\n",
    "        self.n_actions = n_actions\n",
    "        \n",
    "        self.actor_itr = update_actor_interval\n",
    "        self.warmup = warmup\n",
    "        \n",
    "        self.actor = Actor(alpha, ip_dims, n_acts=n_actions, name='actor')\n",
    "        self.critic_1 = Critic(beta, ip_dims, n_acts=n_actions, name='critic_1')\n",
    "        self.critic_2 = Critic(beta, ip_dims, n_acts=n_actions, name='critic_2')\n",
    "        \n",
    "        self.target_actor = Actor(alpha, ip_dims, n_acts=n_actions, name='target_actor')\n",
    "        self.target_critic_1 = Critic(beta, ip_dims, n_acts=n_actions, name='target_critic_1')\n",
    "        self.target_critic_2 = Critic(beta, ip_dims, n_acts=n_actions, name='target_critic_2')\n",
    "        \n",
    "        self.noise = noise\n",
    "        \n",
    "        self.update_network(tau=1)\n",
    "        \n",
    "    \n",
    "    def choose_action(self, observation):\n",
    "        \n",
    "        if self.time_step < self.warmup:\n",
    "            mu = T.tensor(np.random.normal(scale=self.noise, size=(self.n_actions,)))\n",
    "            \n",
    "        else: \n",
    "            state = T.tensor(observation, dtype=T.float).to(self.actor.device)\n",
    "            mu = self.actor.forward(state).to(self.actor.device)\n",
    "            \n",
    "        mu_prime = mu + T.tensor(np.random.normal(scale=self.noise), dtype=T.float).to(self.actor.device)\n",
    "        \n",
    "        mu_prime = T.clamp(mu_prime, self.min_action[0], self.max_action[0])\n",
    "        \n",
    "        self.time_step += 1\n",
    "        \n",
    "        return mu_prime.cpu().detach().numpy()\n",
    "    \n",
    "    def remember(self, state,action, reward, state_, done):\n",
    "        self.memory.store_transition(state, action, reward, state_, done)\n",
    "    \n",
    "    def learn(self):\n",
    "        if self.memory.mean_cntr < self.batch_size:\n",
    "            return \n",
    "        state, action, reward, new_state, done = \\\n",
    "                self.memory.sample_buffer(self.batch_size)\n",
    "\n",
    "        reward = T.tensor(reward, dtype=T.float).to(self.critic_1.device)\n",
    "        done = T.tensor(done).to(self.critic_1.device)\n",
    "        state_ = T.tensor(new_state, dtype=T.float).to(self.critic_1.device)\n",
    "        state = T.tensor(state, dtype=T.float).to(self.critic_1.device)\n",
    "        action = T.tensor(action, dtype=T.float).to(self.critic_1.device)\n",
    "        \n",
    "        target_actions = self.target_actor.forward(state_)\n",
    "        target_actions = target_actions + \\\n",
    "                T.clamp(T.tensor(np.random.normal(scale=0.2)), -0.5, 0.5)\n",
    "        target_actions = T.clamp(target_actions, self.min_action[0], \n",
    "                                self.max_action[0])\n",
    "        \n",
    "        q1_ = self.target_critic_1.forward(state_, target_actions)\n",
    "        q2_ = self.target_critic_2.forward(state_, target_actions)\n",
    "\n",
    "        q1 = self.critic_1.forward(state, action)\n",
    "        q2 = self.critic_2.forward(state, action)\n",
    "\n",
    "        q1_[done] = 0.0\n",
    "        q2_[done] = 0.0\n",
    "\n",
    "        q1_ = q1_.view(-1)\n",
    "        q2_ = q2_.view(-1)\n",
    "\n",
    "        critic_value_ = T.min(q1_, q2_)\n",
    "\n",
    "        target = reward + self.gamma*critic_value_\n",
    "        target = target.view(self.batch_size, 1)\n",
    "\n",
    "        self.critic_1.opt.zero_grad()\n",
    "        self.critic_2.opt.zero_grad()\n",
    "\n",
    "        q1_loss = F.mse_loss(target, q1)\n",
    "        q2_loss = F.mse_loss(target, q2)\n",
    "        critic_loss = q1_loss + q2_loss\n",
    "        critic_loss.backward()\n",
    "        self.critic_1.opt.step()\n",
    "        self.critic_2.opt.step()\n",
    "\n",
    "        self.learning_step_ctr += 1\n",
    "\n",
    "        if self.learning_step_ctr % self.actor_itr != 0:\n",
    "            return\n",
    "\n",
    "        self.actor.opt.zero_grad()\n",
    "        actor_q1_loss = self.critic_1.forward(state, self.actor.forward(state))\n",
    "        actor_loss = -T.mean(actor_q1_loss)\n",
    "        actor_loss.backward()\n",
    "        self.actor.opt.step()\n",
    "\n",
    "        self.update_network()\n",
    "\n",
    "    def update_network(self, tau=None):\n",
    "        if tau is None:\n",
    "            tau = self.tau\n",
    "\n",
    "        actor_params = self.actor.named_parameters()\n",
    "        critic_1_params = self.critic_1.named_parameters()\n",
    "        critic_2_params = self.critic_2.named_parameters()\n",
    "        target_actor_params = self.target_actor.named_parameters()\n",
    "        target_critic_1_params = self.target_critic_1.named_parameters()\n",
    "        target_critic_2_params = self.target_critic_2.named_parameters()\n",
    "\n",
    "        critic_1 = dict(critic_1_params)\n",
    "        critic_2 = dict(critic_2_params)\n",
    "        actor = dict(actor_params)\n",
    "        target_actor = dict(target_actor_params)\n",
    "        target_critic_1 = dict(target_critic_1_params)\n",
    "        target_critic_2 = dict(target_critic_2_params)\n",
    "\n",
    "        for name in critic_1:\n",
    "            critic_1[name] = tau*critic_1[name].clone() + \\\n",
    "                    (1-tau)*target_critic_1[name].clone()\n",
    "\n",
    "        for name in critic_2:\n",
    "            critic_2[name] = tau*critic_2[name].clone() + \\\n",
    "                    (1-tau)*target_critic_2[name].clone()\n",
    "\n",
    "        for name in actor:\n",
    "            actor[name] = tau*actor[name].clone() + \\\n",
    "                    (1-tau)*target_actor[name].clone()\n",
    "\n",
    "        self.target_critic_1.load_state_dict(critic_1)\n",
    "        self.target_critic_2.load_state_dict(critic_2)\n",
    "        self.target_actor.load_state_dict(actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0 score: -104.74 avg_score: -104.74\n",
      "episode: 1 score: -123.86 avg_score: -114.30\n",
      "episode: 2 score: -78.07 avg_score: -102.22\n",
      "episode: 3 score: -158.93 avg_score: -116.40\n",
      "episode: 4 score: -188.35 avg_score: -130.79\n",
      "episode: 5 score: -105.81 avg_score: -126.62\n",
      "episode: 6 score: -72.78 avg_score: -118.93\n",
      "episode: 7 score: -43.27 avg_score: -109.47\n",
      "episode: 8 score: -45.27 avg_score: -102.34\n",
      "episode: 9 score: -225.40 avg_score: -114.65\n",
      "episode: 10 score: -113.63 avg_score: -114.55\n",
      "episode: 11 score: -728.07 avg_score: -165.68\n",
      "episode: 12 score: -497.40 avg_score: -191.20\n",
      "episode: 13 score: -636.70 avg_score: -223.02\n",
      "episode: 14 score: -545.65 avg_score: -244.53\n",
      "episode: 15 score: -536.53 avg_score: -262.78\n",
      "episode: 16 score: -637.19 avg_score: -284.80\n",
      "episode: 17 score: -429.14 avg_score: -292.82\n",
      "episode: 18 score: -713.88 avg_score: -314.98\n",
      "episode: 19 score: -701.70 avg_score: -334.32\n",
      "episode: 20 score: -696.03 avg_score: -351.54\n",
      "episode: 21 score: -758.44 avg_score: -370.04\n",
      "episode: 22 score: -588.15 avg_score: -379.52\n",
      "episode: 23 score: -659.46 avg_score: -391.18\n",
      "episode: 24 score: -721.97 avg_score: -404.42\n",
      "episode: 25 score: -599.04 avg_score: -411.90\n",
      "episode: 26 score: -707.43 avg_score: -422.85\n",
      "episode: 27 score: -470.58 avg_score: -424.55\n",
      "episode: 28 score: -476.25 avg_score: -426.33\n",
      "episode: 29 score: -945.48 avg_score: -443.64\n",
      "episode: 30 score: -1232.17 avg_score: -469.08\n",
      "episode: 31 score: -605.46 avg_score: -473.34\n",
      "episode: 32 score: -471.81 avg_score: -473.29\n",
      "episode: 33 score: -185.41 avg_score: -464.82\n",
      "episode: 34 score: -50.23 avg_score: -452.98\n",
      "episode: 35 score: -240.60 avg_score: -447.08\n",
      "episode: 36 score: -212.81 avg_score: -440.75\n",
      "episode: 37 score: -265.50 avg_score: -436.14\n",
      "episode: 38 score: -259.80 avg_score: -431.61\n",
      "episode: 39 score: -581.47 avg_score: -435.36\n",
      "episode: 40 score: -526.03 avg_score: -437.57\n",
      "episode: 41 score: -161.80 avg_score: -431.01\n",
      "episode: 42 score: -300.50 avg_score: -427.97\n",
      "episode: 43 score: -81.29 avg_score: -420.09\n",
      "episode: 44 score: -156.57 avg_score: -414.24\n",
      "episode: 45 score: -100.96 avg_score: -407.43\n",
      "episode: 46 score: -376.53 avg_score: -406.77\n",
      "episode: 47 score: -153.11 avg_score: -401.48\n",
      "episode: 48 score: -192.31 avg_score: -397.21\n",
      "episode: 49 score: -230.12 avg_score: -393.87\n",
      "episode: 50 score: -88.85 avg_score: -387.89\n",
      "episode: 51 score: -94.21 avg_score: -382.24\n",
      "episode: 52 score: -234.24 avg_score: -379.45\n",
      "episode: 53 score: -321.87 avg_score: -378.39\n",
      "episode: 54 score: -277.67 avg_score: -376.55\n",
      "episode: 55 score: -63.27 avg_score: -370.96\n",
      "episode: 56 score: -160.28 avg_score: -367.26\n",
      "episode: 57 score: -66.34 avg_score: -362.08\n",
      "episode: 58 score: -217.74 avg_score: -359.63\n",
      "episode: 59 score: -105.99 avg_score: -355.40\n",
      "episode: 60 score: -118.45 avg_score: -351.52\n",
      "episode: 61 score: -4.66 avg_score: -345.92\n",
      "episode: 62 score: -117.27 avg_score: -342.29\n",
      "episode: 63 score: -244.83 avg_score: -340.77\n",
      "episode: 64 score: -252.18 avg_score: -339.41\n",
      "episode: 65 score: -191.85 avg_score: -337.17\n",
      "episode: 66 score: -352.67 avg_score: -337.40\n",
      "episode: 67 score: -41.81 avg_score: -333.06\n",
      "episode: 68 score: -85.34 avg_score: -329.47\n",
      "episode: 69 score: -186.06 avg_score: -327.42\n",
      "episode: 70 score: -178.93 avg_score: -325.33\n",
      "episode: 71 score: -152.62 avg_score: -322.93\n",
      "episode: 72 score: -215.45 avg_score: -321.46\n",
      "episode: 73 score: -77.77 avg_score: -318.16\n",
      "episode: 74 score: -95.80 avg_score: -315.20\n",
      "episode: 75 score: -123.13 avg_score: -312.67\n",
      "episode: 76 score: -113.70 avg_score: -310.09\n",
      "episode: 77 score: -189.79 avg_score: -308.54\n",
      "episode: 78 score: -106.75 avg_score: -305.99\n",
      "episode: 79 score: -115.47 avg_score: -303.61\n",
      "episode: 80 score: -150.54 avg_score: -301.72\n",
      "episode: 81 score: -93.34 avg_score: -299.18\n",
      "episode: 82 score: -177.00 avg_score: -297.71\n",
      "episode: 83 score: -109.58 avg_score: -295.47\n",
      "episode: 84 score: -104.00 avg_score: -293.21\n",
      "episode: 85 score: -189.26 avg_score: -292.00\n",
      "episode: 86 score: -138.33 avg_score: -290.24\n",
      "episode: 87 score: -103.04 avg_score: -288.11\n",
      "episode: 88 score: -125.78 avg_score: -286.29\n",
      "episode: 89 score: -94.65 avg_score: -284.16\n",
      "episode: 90 score: -130.12 avg_score: -282.46\n",
      "episode: 91 score: -49.17 avg_score: -279.93\n",
      "episode: 92 score: -169.60 avg_score: -278.74\n",
      "episode: 93 score: -104.77 avg_score: -276.89\n",
      "episode: 94 score: -144.40 avg_score: -275.50\n",
      "episode: 95 score: -60.80 avg_score: -273.26\n",
      "episode: 96 score: -159.67 avg_score: -272.09\n",
      "episode: 97 score: -71.37 avg_score: -270.04\n",
      "episode: 98 score: -93.30 avg_score: -268.26\n",
      "episode: 99 score: -149.25 avg_score: -267.07\n",
      "episode: 100 score: -114.49 avg_score: -267.16\n",
      "episode: 101 score: -399.25 avg_score: -269.92\n",
      "episode: 102 score: -111.69 avg_score: -270.25\n",
      "episode: 103 score: -187.76 avg_score: -270.54\n",
      "episode: 104 score: -109.45 avg_score: -269.75\n",
      "episode: 105 score: -91.19 avg_score: -269.61\n",
      "episode: 106 score: -88.82 avg_score: -269.77\n",
      "episode: 107 score: -148.46 avg_score: -270.82\n",
      "episode: 108 score: -217.65 avg_score: -272.54\n",
      "episode: 109 score: -113.00 avg_score: -271.42\n",
      "episode: 110 score: -219.67 avg_score: -272.48\n",
      "episode: 111 score: -181.20 avg_score: -267.01\n",
      "episode: 112 score: -96.72 avg_score: -263.00\n",
      "episode: 113 score: -268.11 avg_score: -259.32\n",
      "episode: 114 score: -153.97 avg_score: -255.40\n",
      "episode: 115 score: -352.89 avg_score: -253.57\n",
      "episode: 116 score: -218.70 avg_score: -249.38\n",
      "episode: 117 score: -165.95 avg_score: -246.75\n",
      "episode: 118 score: -143.90 avg_score: -241.05\n",
      "episode: 119 score: -175.15 avg_score: -235.78\n",
      "episode: 120 score: -199.53 avg_score: -230.82\n",
      "episode: 121 score: -103.90 avg_score: -224.27\n",
      "episode: 122 score: -137.70 avg_score: -219.77\n",
      "episode: 123 score: -36.19 avg_score: -213.54\n",
      "episode: 124 score: -128.00 avg_score: -207.60\n",
      "episode: 125 score: -113.02 avg_score: -202.74\n",
      "episode: 126 score: -364.06 avg_score: -199.30\n",
      "episode: 127 score: -111.12 avg_score: -195.71\n",
      "episode: 128 score: -256.84 avg_score: -193.51\n",
      "episode: 129 score: -43.25 avg_score: -184.49\n",
      "episode: 130 score: -50.24 avg_score: -172.67\n",
      "episode: 131 score: -234.08 avg_score: -168.96\n",
      "episode: 132 score: -28.07 avg_score: -164.52\n",
      "episode: 133 score: 6.27 avg_score: -162.60\n",
      "episode: 134 score: -98.59 avg_score: -163.09\n",
      "episode: 135 score: -80.28 avg_score: -161.48\n",
      "episode: 136 score: -79.43 avg_score: -160.15\n",
      "episode: 137 score: -53.18 avg_score: -158.03\n",
      "episode: 138 score: -41.35 avg_score: -155.84\n",
      "episode: 139 score: -41.28 avg_score: -150.44\n",
      "episode: 140 score: 72.87 avg_score: -144.45\n",
      "episode: 141 score: -43.83 avg_score: -143.27\n",
      "episode: 142 score: -98.11 avg_score: -141.25\n",
      "episode: 143 score: -61.56 avg_score: -141.05\n",
      "episode: 144 score: -33.29 avg_score: -139.82\n",
      "episode: 145 score: -19.86 avg_score: -139.01\n",
      "episode: 146 score: -280.48 avg_score: -138.05\n",
      "episode: 147 score: 37.88 avg_score: -136.14\n",
      "episode: 148 score: -9.36 avg_score: -134.31\n",
      "episode: 149 score: -272.35 avg_score: -134.73\n",
      "episode: 150 score: -151.90 avg_score: -135.36\n",
      "episode: 151 score: -276.68 avg_score: -137.18\n",
      "episode: 152 score: 135.09 avg_score: -133.49\n",
      "episode: 153 score: -68.66 avg_score: -130.96\n",
      "episode: 154 score: -259.84 avg_score: -130.78\n",
      "episode: 155 score: -12.27 avg_score: -130.27\n",
      "episode: 156 score: 140.75 avg_score: -127.26\n",
      "episode: 157 score: -116.04 avg_score: -127.76\n",
      "episode: 158 score: -5.95 avg_score: -125.64\n",
      "episode: 159 score: 2.34 avg_score: -124.56\n",
      "episode: 160 score: -103.74 avg_score: -124.41\n",
      "episode: 161 score: 18.25 avg_score: -124.18\n",
      "episode: 162 score: -91.83 avg_score: -123.93\n",
      "episode: 163 score: -29.58 avg_score: -121.77\n",
      "episode: 164 score: 10.76 avg_score: -119.14\n",
      "episode: 165 score: -219.79 avg_score: -119.42\n",
      "episode: 166 score: -22.70 avg_score: -116.12\n",
      "episode: 167 score: -0.56 avg_score: -115.71\n",
      "episode: 168 score: -23.35 avg_score: -115.09\n",
      "episode: 169 score: 36.40 avg_score: -112.87\n",
      "episode: 170 score: 20.07 avg_score: -110.88\n",
      "episode: 171 score: 39.64 avg_score: -108.95\n",
      "episode: 172 score: -102.79 avg_score: -107.83\n",
      "episode: 173 score: 38.05 avg_score: -106.67\n",
      "episode: 174 score: -79.14 avg_score: -106.50\n",
      "episode: 175 score: 76.18 avg_score: -104.51\n",
      "episode: 176 score: 204.24 avg_score: -101.33\n",
      "episode: 177 score: 226.97 avg_score: -97.16\n",
      "episode: 178 score: 134.13 avg_score: -94.75\n",
      "episode: 179 score: 244.81 avg_score: -91.15\n",
      "episode: 180 score: 181.56 avg_score: -87.83\n",
      "episode: 181 score: 254.62 avg_score: -84.35\n",
      "episode: 182 score: 135.19 avg_score: -81.23\n",
      "episode: 183 score: 186.43 avg_score: -78.27\n",
      "episode: 184 score: 159.76 avg_score: -75.63\n",
      "episode: 185 score: 261.89 avg_score: -71.12\n",
      "episode: 186 score: -23.94 avg_score: -69.97\n",
      "episode: 187 score: 264.13 avg_score: -66.30\n",
      "episode: 188 score: 14.77 avg_score: -64.90\n",
      "episode: 189 score: -48.95 avg_score: -64.44\n",
      "episode: 190 score: -63.33 avg_score: -63.77\n",
      "episode: 191 score: 118.06 avg_score: -62.10\n",
      "episode: 192 score: 236.43 avg_score: -58.04\n",
      "episode: 193 score: 192.11 avg_score: -55.07\n",
      "episode: 194 score: 234.44 avg_score: -51.28\n",
      "episode: 195 score: -107.25 avg_score: -51.75\n",
      "episode: 196 score: 135.82 avg_score: -48.79\n",
      "episode: 197 score: 179.95 avg_score: -46.28\n",
      "episode: 198 score: -96.38 avg_score: -46.31\n",
      "episode: 199 score: -49.57 avg_score: -45.31\n",
      "episode: 200 score: -47.34 avg_score: -44.64\n",
      "episode: 201 score: -2259.13 avg_score: -63.24\n",
      "episode: 202 score: -70.36 avg_score: -62.83\n",
      "episode: 203 score: -26.25 avg_score: -61.21\n",
      "episode: 204 score: 111.25 avg_score: -59.00\n",
      "episode: 205 score: 149.69 avg_score: -56.60\n",
      "episode: 206 score: 139.94 avg_score: -54.31\n",
      "episode: 207 score: 39.71 avg_score: -52.43\n",
      "episode: 208 score: -4.27 avg_score: -50.29\n",
      "episode: 209 score: 148.21 avg_score: -47.68\n",
      "episode: 210 score: -34.15 avg_score: -45.83\n",
      "episode: 211 score: 135.92 avg_score: -42.65\n",
      "episode: 212 score: 189.80 avg_score: -39.79\n",
      "episode: 213 score: 236.23 avg_score: -34.75\n",
      "episode: 214 score: 227.07 avg_score: -30.94\n",
      "episode: 215 score: 167.93 avg_score: -25.73\n",
      "episode: 216 score: 197.03 avg_score: -21.57\n",
      "episode: 217 score: 250.36 avg_score: -17.41\n",
      "episode: 218 score: 244.55 avg_score: -13.52\n",
      "episode: 219 score: 36.37 avg_score: -11.41\n",
      "episode: 220 score: -35.27 avg_score: -9.76\n",
      "episode: 221 score: 202.33 avg_score: -6.70\n",
      "episode: 222 score: 308.57 avg_score: -2.24\n",
      "episode: 223 score: 233.83 avg_score: 0.46\n",
      "episode: 224 score: 183.10 avg_score: 3.57\n",
      "episode: 225 score: 269.81 avg_score: 7.40\n",
      "episode: 226 score: 16.92 avg_score: 11.21\n",
      "episode: 227 score: 238.11 avg_score: 14.70\n",
      "episode: 228 score: 216.44 avg_score: 19.43\n",
      "episode: 229 score: 0.87 avg_score: 19.88\n",
      "episode: 230 score: 193.27 avg_score: 22.31\n",
      "episode: 231 score: 231.29 avg_score: 26.96\n",
      "episode: 232 score: 299.99 avg_score: 30.25\n",
      "episode: 233 score: 146.31 avg_score: 31.65\n",
      "episode: 234 score: 175.69 avg_score: 34.39\n",
      "episode: 235 score: 273.34 avg_score: 37.92\n",
      "episode: 236 score: 294.55 avg_score: 41.66\n",
      "episode: 237 score: 228.73 avg_score: 44.48\n",
      "episode: 238 score: 222.99 avg_score: 47.13\n",
      "episode: 239 score: 268.95 avg_score: 50.23\n",
      "episode: 240 score: 283.58 avg_score: 52.34\n",
      "episode: 241 score: 253.49 avg_score: 55.31\n",
      "episode: 242 score: 235.17 avg_score: 58.64\n",
      "episode: 243 score: 237.77 avg_score: 61.64\n",
      "episode: 244 score: 252.21 avg_score: 64.49\n",
      "episode: 245 score: 244.76 avg_score: 67.14\n",
      "episode: 246 score: 297.84 avg_score: 72.92\n",
      "episode: 247 score: 291.66 avg_score: 75.46\n",
      "episode: 248 score: 257.14 avg_score: 78.12\n",
      "episode: 249 score: 281.11 avg_score: 83.66\n",
      "episode: 250 score: 37.18 avg_score: 85.55\n",
      "episode: 251 score: 267.46 avg_score: 90.99\n",
      "episode: 252 score: 236.90 avg_score: 92.01\n",
      "episode: 253 score: 288.21 avg_score: 95.58\n",
      "episode: 254 score: 298.23 avg_score: 101.16\n",
      "episode: 255 score: 271.25 avg_score: 103.99\n",
      "episode: 256 score: 282.32 avg_score: 105.41\n",
      "episode: 257 score: 263.70 avg_score: 109.21\n",
      "episode: 258 score: 303.02 avg_score: 112.29\n",
      "episode: 259 score: 239.79 avg_score: 114.67\n",
      "episode: 260 score: 308.79 avg_score: 118.79\n",
      "episode: 261 score: 235.99 avg_score: 120.97\n",
      "episode: 262 score: -68.94 avg_score: 121.20\n",
      "episode: 263 score: -18.36 avg_score: 121.31\n",
      "episode: 264 score: 295.92 avg_score: 124.16\n",
      "episode: 265 score: 272.49 avg_score: 129.09\n",
      "episode: 266 score: 218.51 avg_score: 131.50\n",
      "episode: 267 score: 228.28 avg_score: 133.79\n",
      "episode: 268 score: 235.80 avg_score: 136.38\n",
      "episode: 269 score: 258.16 avg_score: 138.60\n",
      "episode: 270 score: 274.23 avg_score: 141.14\n",
      "episode: 271 score: -105.24 avg_score: 139.69\n",
      "episode: 272 score: 247.83 avg_score: 143.20\n",
      "episode: 273 score: 211.02 avg_score: 144.93\n",
      "episode: 274 score: 216.31 avg_score: 147.88\n",
      "episode: 275 score: -24.58 avg_score: 146.87\n",
      "episode: 276 score: -23.68 avg_score: 144.59\n",
      "episode: 277 score: 172.52 avg_score: 144.05\n",
      "episode: 278 score: 244.27 avg_score: 145.15\n",
      "episode: 279 score: 261.39 avg_score: 145.32\n",
      "episode: 280 score: -30.28 avg_score: 143.20\n",
      "episode: 281 score: 220.07 avg_score: 142.85\n",
      "episode: 282 score: 247.38 avg_score: 143.97\n",
      "episode: 283 score: -14.04 avg_score: 141.97\n",
      "episode: 284 score: 210.63 avg_score: 142.48\n",
      "episode: 285 score: 261.60 avg_score: 142.48\n",
      "episode: 286 score: 187.18 avg_score: 144.59\n",
      "episode: 287 score: 24.40 avg_score: 142.19\n",
      "episode: 288 score: 242.50 avg_score: 144.47\n",
      "episode: 289 score: 231.75 avg_score: 147.27\n",
      "episode: 290 score: 245.62 avg_score: 150.36\n",
      "episode: 291 score: 215.05 avg_score: 151.33\n",
      "episode: 292 score: 270.24 avg_score: 151.67\n",
      "episode: 293 score: 258.42 avg_score: 152.33\n",
      "episode: 294 score: 180.59 avg_score: 151.80\n",
      "episode: 295 score: 272.26 avg_score: 155.59\n",
      "episode: 296 score: 1.48 avg_score: 154.25\n",
      "episode: 297 score: -12.59 avg_score: 152.32\n",
      "episode: 298 score: 217.15 avg_score: 155.46\n",
      "episode: 299 score: -58.32 avg_score: 155.37\n",
      "episode: 300 score: 198.88 avg_score: 157.83\n",
      "episode: 301 score: 172.77 avg_score: 182.15\n",
      "episode: 302 score: 257.09 avg_score: 185.43\n",
      "episode: 303 score: 211.32 avg_score: 187.80\n",
      "episode: 304 score: 218.45 avg_score: 188.87\n",
      "episode: 305 score: 181.34 avg_score: 189.19\n",
      "episode: 306 score: 234.69 avg_score: 190.14\n",
      "episode: 307 score: 278.47 avg_score: 192.52\n",
      "episode: 308 score: 231.23 avg_score: 194.88\n",
      "episode: 309 score: 253.53 avg_score: 195.93\n",
      "episode: 310 score: 175.81 avg_score: 198.03\n",
      "episode: 311 score: 273.92 avg_score: 199.41\n",
      "episode: 312 score: 12.26 avg_score: 197.64\n",
      "episode: 313 score: 256.98 avg_score: 197.84\n",
      "episode: 314 score: 83.35 avg_score: 196.41\n",
      "episode: 315 score: -32.44 avg_score: 194.40\n",
      "episode: 316 score: 216.72 avg_score: 194.60\n",
      "episode: 317 score: 234.04 avg_score: 194.44\n",
      "episode: 318 score: -6.09 avg_score: 191.93\n",
      "episode: 319 score: 240.17 avg_score: 193.97\n",
      "episode: 320 score: 207.21 avg_score: 196.39\n",
      "episode: 321 score: 274.00 avg_score: 197.11\n",
      "episode: 322 score: 238.73 avg_score: 196.41\n",
      "episode: 323 score: 17.72 avg_score: 194.25\n",
      "episode: 324 score: 211.62 avg_score: 194.54\n",
      "episode: 325 score: 251.56 avg_score: 194.35\n",
      "episode: 326 score: 217.85 avg_score: 196.36\n",
      "episode: 327 score: 267.84 avg_score: 196.66\n",
      "episode: 328 score: 1.46 avg_score: 194.51\n",
      "episode: 329 score: 214.14 avg_score: 196.64\n",
      "episode: 330 score: 196.14 avg_score: 196.67\n",
      "episode: 331 score: 214.76 avg_score: 196.51\n",
      "episode: 332 score: 257.21 avg_score: 196.08\n",
      "episode: 333 score: 302.90 avg_score: 197.64\n",
      "episode: 334 score: 202.15 avg_score: 197.91\n",
      "episode: 335 score: 227.77 avg_score: 197.45\n",
      "episode: 336 score: 219.13 avg_score: 196.70\n",
      "episode: 337 score: 295.77 avg_score: 197.37\n",
      "episode: 338 score: 234.53 avg_score: 197.48\n",
      "episode: 339 score: 28.07 avg_score: 195.08\n",
      "episode: 340 score: 284.43 avg_score: 195.08\n",
      "episode: 341 score: 279.00 avg_score: 195.34\n",
      "episode: 342 score: 264.97 avg_score: 195.64\n",
      "episode: 343 score: 292.16 avg_score: 196.18\n",
      "episode: 344 score: 247.27 avg_score: 196.13\n",
      "episode: 345 score: 36.99 avg_score: 194.05\n",
      "episode: 346 score: 267.63 avg_score: 193.75\n",
      "episode: 347 score: 240.30 avg_score: 193.24\n",
      "episode: 348 score: 249.75 avg_score: 193.16\n",
      "episode: 349 score: 177.13 avg_score: 192.12\n",
      "episode: 350 score: 300.13 avg_score: 194.75\n",
      "episode: 351 score: 15.27 avg_score: 192.23\n",
      "episode: 352 score: 290.03 avg_score: 192.76\n",
      "episode: 353 score: 41.33 avg_score: 190.29\n",
      "episode: 354 score: 252.53 avg_score: 189.84\n",
      "episode: 355 score: 298.66 avg_score: 190.11\n",
      "episode: 356 score: 51.50 avg_score: 187.80\n",
      "episode: 357 score: 241.51 avg_score: 187.58\n",
      "episode: 358 score: -6.81 avg_score: 184.48\n",
      "episode: 359 score: 277.44 avg_score: 184.86\n",
      "episode: 360 score: 10.83 avg_score: 181.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 361 score: 268.59 avg_score: 182.21\n",
      "episode: 362 score: -1.38 avg_score: 182.88\n",
      "episode: 363 score: 11.53 avg_score: 183.18\n",
      "episode: 364 score: 31.34 avg_score: 180.53\n",
      "episode: 365 score: 243.53 avg_score: 180.25\n",
      "episode: 366 score: 267.96 avg_score: 180.74\n",
      "episode: 367 score: 281.19 avg_score: 181.27\n",
      "episode: 368 score: 0.96 avg_score: 178.92\n",
      "episode: 369 score: 270.74 avg_score: 179.05\n",
      "episode: 370 score: 249.01 avg_score: 178.79\n",
      "episode: 371 score: 270.05 avg_score: 182.55\n",
      "episode: 372 score: 263.42 avg_score: 182.70\n",
      "episode: 373 score: 249.67 avg_score: 183.09\n",
      "episode: 374 score: 13.08 avg_score: 181.06\n",
      "episode: 375 score: 8.29 avg_score: 181.39\n",
      "episode: 376 score: 174.15 avg_score: 183.36\n",
      "episode: 377 score: 277.18 avg_score: 184.41\n",
      "episode: 378 score: 232.38 avg_score: 184.29\n",
      "episode: 379 score: 291.31 avg_score: 184.59\n",
      "episode: 380 score: -22.79 avg_score: 184.67\n",
      "episode: 381 score: 216.36 avg_score: 184.63\n",
      "episode: 382 score: 235.75 avg_score: 184.51\n",
      "episode: 383 score: 263.73 avg_score: 187.29\n",
      "episode: 384 score: 276.52 avg_score: 187.95\n",
      "episode: 385 score: 213.85 avg_score: 187.47\n",
      "episode: 386 score: 259.16 avg_score: 188.19\n",
      "episode: 387 score: -67.51 avg_score: 187.27\n",
      "episode: 388 score: 198.95 avg_score: 186.84\n",
      "episode: 389 score: 149.07 avg_score: 186.01\n",
      "episode: 390 score: 218.49 avg_score: 185.74\n",
      "episode: 391 score: 199.85 avg_score: 185.59\n",
      "episode: 392 score: 94.44 avg_score: 183.83\n",
      "episode: 393 score: 223.81 avg_score: 183.48\n",
      "episode: 394 score: 256.47 avg_score: 184.24\n",
      "episode: 395 score: 107.40 avg_score: 182.59\n",
      "episode: 396 score: 168.99 avg_score: 184.27\n",
      "episode: 397 score: 214.00 avg_score: 186.53\n",
      "episode: 398 score: 206.70 avg_score: 186.43\n",
      "episode: 399 score: -21.88 avg_score: 186.79\n",
      "episode: 400 score: 248.37 avg_score: 187.29\n",
      "episode: 401 score: 266.61 avg_score: 188.23\n",
      "episode: 402 score: 286.83 avg_score: 188.52\n",
      "episode: 403 score: 203.12 avg_score: 188.44\n",
      "episode: 404 score: 180.63 avg_score: 188.06\n",
      "episode: 405 score: 251.02 avg_score: 188.76\n",
      "episode: 406 score: 270.10 avg_score: 189.12\n",
      "episode: 407 score: 229.95 avg_score: 188.63\n",
      "episode: 408 score: 236.28 avg_score: 188.68\n",
      "episode: 409 score: 247.64 avg_score: 188.62\n",
      "episode: 410 score: 183.15 avg_score: 188.69\n",
      "episode: 411 score: 247.70 avg_score: 188.43\n",
      "episode: 412 score: 260.58 avg_score: 190.92\n",
      "episode: 413 score: 197.01 avg_score: 190.32\n",
      "episode: 414 score: 250.32 avg_score: 191.99\n",
      "episode: 415 score: 265.65 avg_score: 194.97\n",
      "episode: 416 score: 250.84 avg_score: 195.31\n",
      "episode: 417 score: 192.58 avg_score: 194.89\n",
      "episode: 418 score: 230.28 avg_score: 197.26\n",
      "episode: 419 score: 222.80 avg_score: 197.08\n",
      "episode: 420 score: 241.39 avg_score: 197.43\n",
      "episode: 421 score: 5.68 avg_score: 194.74\n",
      "episode: 422 score: 227.52 avg_score: 194.63\n",
      "episode: 423 score: 282.66 avg_score: 197.28\n",
      "episode: 424 score: 254.74 avg_score: 197.71\n",
      "episode: 425 score: 268.40 avg_score: 197.88\n",
      "episode: 426 score: 214.85 avg_score: 197.85\n",
      "episode: 427 score: 244.49 avg_score: 197.62\n",
      "episode: 428 score: 258.08 avg_score: 200.18\n",
      "episode: 429 score: 231.27 avg_score: 200.35\n",
      "episode: 430 score: 208.86 avg_score: 200.48\n",
      "episode: 431 score: 263.10 avg_score: 200.96\n",
      "episode: 432 score: 241.72 avg_score: 200.81\n",
      "episode: 433 score: 259.25 avg_score: 200.37\n",
      "episode: 434 score: 29.41 avg_score: 198.65\n",
      "episode: 435 score: 258.63 avg_score: 198.95\n",
      "episode: 436 score: 191.08 avg_score: 198.67\n",
      "episode: 437 score: 253.90 avg_score: 198.25\n",
      "episode: 438 score: 217.83 avg_score: 198.09\n",
      "episode: 439 score: 216.26 avg_score: 199.97\n",
      "episode: 440 score: 139.76 avg_score: 198.52\n",
      "episode: 441 score: 231.11 avg_score: 198.04\n",
      "episode: 442 score: 215.20 avg_score: 197.55\n",
      "episode: 443 score: 211.46 avg_score: 196.74\n",
      "episode: 444 score: 228.64 avg_score: 196.55\n",
      "episode: 445 score: 2.74 avg_score: 196.21\n",
      "episode: 446 score: 239.58 avg_score: 195.93\n",
      "episode: 447 score: -167.74 avg_score: 191.85\n",
      "episode: 448 score: 248.87 avg_score: 191.84\n",
      "episode: 449 score: 256.50 avg_score: 192.63\n",
      "episode: 450 score: 206.67 avg_score: 191.70\n",
      "episode: 451 score: 228.36 avg_score: 193.83\n",
      "episode: 452 score: 269.79 avg_score: 193.63\n",
      "episode: 453 score: 250.83 avg_score: 195.72\n",
      "episode: 454 score: 249.30 avg_score: 195.69\n",
      "episode: 455 score: 231.83 avg_score: 195.02\n",
      "episode: 456 score: 204.34 avg_score: 196.55\n",
      "episode: 457 score: 214.67 avg_score: 196.28\n",
      "episode: 458 score: 249.52 avg_score: 198.85\n",
      "episode: 459 score: 26.95 avg_score: 196.34\n",
      "episode: 460 score: 193.59 avg_score: 198.17\n",
      "episode: 461 score: 226.69 avg_score: 197.75\n",
      "episode: 462 score: 227.53 avg_score: 200.04\n",
      "episode: 463 score: 217.37 avg_score: 202.10\n",
      "episode: 464 score: -176.57 avg_score: 200.02\n",
      "episode: 465 score: 179.36 avg_score: 199.38\n",
      "episode: 466 score: 125.00 avg_score: 197.95\n"
     ]
    }
   ],
   "source": [
    "import gym \n",
    "import numpy as np\n",
    "\n",
    "def plotLearning(scores, filename, x=None, window=5):\n",
    "    N = len(scores)\n",
    "    running_avg = np.empty(N)\n",
    "    for t in range(N):\n",
    "        running_avg[t] = np.mean(scores[max(0, t-window):(t+1)])\n",
    "    if x is None:\n",
    "        x = [i for i in range(N)]\n",
    "    plt.ylabel('Score')       \n",
    "    plt.xlabel('Game')                     \n",
    "    plt.plot(x, running_avg)\n",
    "    plt.savefig(filename)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    env = gym.make('LunarLanderContinuous-v2')\n",
    "    \n",
    "    agent  = Agent(alpha=0.001, beta=0.001, ip_dims=env.observation_space.shape,\\\n",
    "                   tau=0.005, env=env, batch_size=100, n_actions=env.action_space.shape[0])\n",
    "    \n",
    "    \n",
    "    n_games = 1000\n",
    "    file_name = 'plots/'+'LunarLunderContinuous_'+' '+str(n_games)+'_games.png'\n",
    "    \n",
    "    best_score= env.reward_range[0]\n",
    "    \n",
    "    score_hist = []\n",
    "    \n",
    "    #agent.load_model()\n",
    "    for i in range(n_games):\n",
    "        \n",
    "        observation = env.reset()\n",
    "        done = False\n",
    "        score = 0\n",
    "        \n",
    "        while not done:\n",
    "            action = agent.choose_action(observation)\n",
    "            observation_, reward, done, info = env.step(action)\n",
    "            agent.remember(observation, action, reward, observation_, done)\n",
    "            agent.learn()\n",
    "            \n",
    "            score += reward\n",
    "            \n",
    "            observation = observation_\n",
    "            \n",
    "        score_hist.append(score)\n",
    "        \n",
    "        avg_score = np.mean(score_hist[-100:])\n",
    "        \n",
    "        if avg_score > best_score:\n",
    "            best_score = avg_score\n",
    "            #agent.save_model()\n",
    "        print('episode:', i, 'score: %.2f' %score, 'avg_score: %.2f' %avg_score)\n",
    "    plotLearning(score_hist, filename=file_name, window=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
